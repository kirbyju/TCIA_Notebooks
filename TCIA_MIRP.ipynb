{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd9874-b86a-4756-be85-7215b8187f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# install mirp\n",
    "!{sys.executable} -m pip install --upgrade -q mirp\n",
    "\n",
    "# install tcia utils for downloading example data\n",
    "!{sys.executable} -m pip install --upgrade -q tcia_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8281cb-4401-4f08-81e5-4e53fcf257f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mirp import extract_mask_labels\n",
    "from mirp import extract_image_parameters\n",
    "from mirp import extract_images\n",
    "from mirp import extract_features\n",
    "import pandas as pd\n",
    "from tcia_utils import nbia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae3fea-344e-4313-806d-7cbfcaf6eff1",
   "metadata": {},
   "source": [
    "# Download example data\n",
    "\n",
    "In this example we will use the [Soft-tissue-Sarcoma](http://doi.org/10.7937/K9/TCIA.2015.7GO2GSKS) dataset from The Cancer Imaging Archive.  Please be sure to abide by the [TCIA Data Usage Policy and Restrictions](https://www.cancerimagingarchive.net/data-usage-policies-and-restrictions/) by including this citation anywhere these data are being discussed:\n",
    "\n",
    "```Valli√®res, Martin, Freeman, Carolyn R., Skamene, Sonia R., & El Naqa, Issam. (2015). A radiomics model from joint FDG-PET and MRI texture features for the prediction of lung metastases in soft-tissue sarcomas of the extremities (Soft-tissue-Sarcoma) [Dataset]. The Cancer Imaging Archive. http://doi.org/10.7937/K9/TCIA.2015.7GO2GSKS```\n",
    "\n",
    "In order to download the data we'll utilize [tcia_utils](https://pypi.org/project/tcia-utils/).  These commands will demonstrate how to create a dataframe of image and segmentation metadata that we can use to execute mirp commands, as well as how to download the segmentations (RTSTRUCT) and reference MRIs to a folder called `tciaDownload/< SeriesInstanceUID`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ffaa05-6adc-4413-8e95-b9aa6b525642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download an inventory of all scans in the Soft-tissue-Sarcoma dataset\n",
    "series_metadata = nbia.getSeries(collection = \"Soft-tissue-Sarcoma\", format = \"df\")\n",
    "\n",
    "# sort it display the first subject's scans\n",
    "series_metadata = series_metadata.sort_values(by=['PatientID', 'StudyInstanceUID', 'SeriesNumber'], ascending=[True, True, True])\n",
    "series_metadata[series_metadata['PatientID'].isin(series_metadata['PatientID'].unique()[:1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38db50-6ef9-404c-b934-38944925188b",
   "metadata": {},
   "source": [
    "After reviewing the data, let's say we want to focus on the T1 segmentations.  First we'll extract the SeriesInstanceUIDs and other key information to a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba0c06-e284-439a-b7d2-a7526b91d10e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy only the \"RTstruct_T1\" segmentation metadata to a new dataframe\n",
    "seg_metadata = series_metadata[series_metadata['SeriesDescription'] == \"RTstruct_T1\"].copy().reset_index(drop=True)\n",
    "seg_metadata = seg_metadata[['PatientID', 'StudyInstanceUID', 'SeriesInstanceUID', 'SeriesDescription', 'Modality', 'BodyPartExamined']]\n",
    "\n",
    "seg_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b98784-c64c-439c-9cee-72df3aa9c906",
   "metadata": {},
   "source": [
    "Next we'll add a ReferencedSeriesInstanceUID column and use the TCIA API to look up the SeriesInstanceUID of the original T1 scans that were segmented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2562a-4469-4517-ba35-483e597fe9ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an empty list to store the referenced series instance UIDs\n",
    "referenced_series_uids = []\n",
    "\n",
    "# Iterate through each row in the DataFrame and fetch the referenced series instance UID\n",
    "for index, row in seg_metadata.iterrows():\n",
    "    series_instance_uid = row['SeriesInstanceUID']\n",
    "    referenced_series_uid = nbia.getSegRefSeries(series_instance_uid)\n",
    "    referenced_series_uids.append(referenced_series_uid)\n",
    "\n",
    "# Add the list of referenced series instance UIDs as a new column in the DataFrame\n",
    "seg_metadata['ReferencedSeriesInstanceUID'] = referenced_series_uids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463cba67-b8d3-439d-9d8c-d032c1fe53fa",
   "metadata": {},
   "source": [
    "Now we can download some images.  We'll start with 3 subjects, but you can change or remove the number parameter if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b89b13-81d8-45ce-9711-4bc7966066c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the number of patients or use None to download the full set of scans\n",
    "num_patients = 3\n",
    "\n",
    "if num_patients is None:\n",
    "    uids_list = list(seg_metadata['SeriesInstanceUID']) + list(seg_metadata['ReferencedSeriesInstanceUID'])\n",
    "else:\n",
    "    selected_patients = seg_metadata.head(num_patients)\n",
    "    uids_list = list(selected_patients['SeriesInstanceUID']) + list(selected_patients['ReferencedSeriesInstanceUID'])\n",
    "\n",
    "# Pass the uids_list to nbia.downloadSeries(uids) for downloading\n",
    "nbia.downloadSeries(uids_list, input_type = \"list\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9a749-7ea7-4fce-abc2-0932656f7720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb82569-4bbe-4a07-b351-7996d46aef6e",
   "metadata": {},
   "source": [
    "# Finding mask labels\n",
    "\n",
    "Radiomics features are typically computed from regions of interest, such as a tumour. These regions are delineated by experts or auto-segmentation AI, and stored as segmentation masks. MIRP needs to know which mask label (region of interest) should be used for computing features. A first step is to identify which mask labels exist. This can be done using the extract_mask_labels function. We can use our previously created dataframe to tell MIRP where the masks can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c5789-ac3e-47d9-8552-848f68784741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the concatenated results\n",
    "all_labels = pd.DataFrame()\n",
    "\n",
    "# Loop through the selected_patients DataFrame\n",
    "for index, row in selected_patients.iterrows():\n",
    "    # Set seg_path for each row\n",
    "    seg_path = \"tciaDownload/\" + row['SeriesInstanceUID'] + \"/1-1.dcm\"\n",
    "    # Set labels by calling extract_mask_labels(mask = seg_path)\n",
    "    labels = extract_mask_labels(mask=seg_path)\n",
    "    \n",
    "    # Concatenate the results into the all_labels DataFrame\n",
    "    all_labels = pd.concat([all_labels, labels])\n",
    "    \n",
    "all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50d0fd-9518-40d3-bcf0-0b479386cb9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "We are lucky that all masks are consistently labelled. GTV_Mass and GTV_Edema both refer to the gross tumour volume, i.e. that part of the tumour that is visible in medical imaging. GTV-Edema also covers fluid surrounding the gross tumour volume itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77389ecf-9e71-49ff-a452-e9c2a372e4e0",
   "metadata": {},
   "source": [
    "# Visualising images\n",
    "It is often useful to inspect images before computing radiomics features. External viewers for DICOM and many other image types exist, but MIRP also has a simple visualisation tool. You can visualise images by exporting them in MIRP internal formats using extract_images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55948224-d403-49aa-9646-9b0e01c1f06b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e65b55d-dcb7-4ab0-9ade-23ff65db5b50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose a patient to visualize\n",
    "patient_id = \"STS_003\"\n",
    "\n",
    "# filter the dataframe to that patient\n",
    "selected_patient = selected_patients[selected_patients['PatientID'] == patient_id]\n",
    "\n",
    "# Set seg_path and image_path\n",
    "for index, row in selected_patient.iterrows():\n",
    "    seg_path = \"tciaDownload/\" + row['SeriesInstanceUID'] + \"/1-1.dcm\"\n",
    "    image_path = \"tciaDownload/\" + row['ReferencedSeriesInstanceUID']\n",
    "\n",
    "# extract parameters\n",
    "images = extract_images(image = image_path, \n",
    "                            mask = seg_path,\n",
    "                            roi_name = \"GTV_Mass\",\n",
    "                            image_export_format = \"native\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d626e7-1932-4dfa-b6cb-fae718ab2ede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image, mask = images[0]\n",
    "image[0].show(mask=mask[0], slice_id=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9577fba-17b5-42cf-adb9-c9e9bae477d8",
   "metadata": {},
   "source": [
    "There's also a tcia_utils function for this you might want to try.  It'd be great if we could collaborate on this in the future so we're not both maintaining something to do this.  I'd much rather not be in the business of doing visualization if you're interested in rolling this function into your tool and improving it (there are issues with some image modalities and segmentation types) but I couldn't find anything super simple to do what we're both trying to achieve here so I had a summer intern help put this together last year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66834b76-699f-43a0-9016-4dc5f66e3733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nbia.viewSeriesAnnotation(seriesPath = image_path, annotationPath = seg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e393bf6e-207b-4390-a2b3-f837fea12978",
   "metadata": {},
   "source": [
    "# Assessing image metadata\n",
    "Image metadata are important for understanding the image and how it was acquired and reconstructed. MIRP allows for exporting image metadata from DICOM and other image formats, though for non-DICOM formats metadata will be considerably more limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f5aad0-808c-4506-b2d7-6d353d3f73ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the concatenated results\n",
    "all_parameters = pd.DataFrame()\n",
    "\n",
    "# Loop through the selected_patients DataFrame\n",
    "for index, row in selected_patients.iterrows():\n",
    "    # Set seg_path for each row\n",
    "    image_path = \"tciaDownload/\" + row['ReferencedSeriesInstanceUID']\n",
    "    # Extract parameters for each image series\n",
    "    parameters = extract_image_parameters(image = image_path)\n",
    "    \n",
    "    # Concatenate the results into the all_labels DataFrame\n",
    "    all_parameters = pd.concat([all_parameters, parameters])\n",
    "    \n",
    "all_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65ea246-1f71-4fa2-9527-62d26bd22103",
   "metadata": {},
   "source": [
    "Only known metadata are shown. For example, magnetic field strength was not present in the image metadata in this example.\n",
    "\n",
    "The metadata have important implications for the image processing:\n",
    "\n",
    "* The in-plane resolution is much higher than the distance between slices. This suggests that features should be computed by slice, instead in 3D.\n",
    "* The in-plane resolution differs between patients. This suggests that the images should be resampled to isotropic pixel sizes, e.g. 1.0 by 1.0 mm.\n",
    "* All three images were recorded in different scanners. This suggests that MR intensities cannot be compared between patients, and should be standardised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10358f-80f1-43a5-ab08-aa326dd4147b",
   "metadata": {},
   "source": [
    "# Computing features\n",
    "The presented metadata suggest that image processing is required to make the MR images more comparable between patients. We will define three image processing steps:\n",
    "\n",
    "1. Image processing and feature computation is performed by slice (by_slice=True) due to large distances between image slices.\n",
    "2. In-plane resolution is resampled to 1.0 by 1.0 mm (new_spacing=1.0).\n",
    "3. Intensities are normalised, here using z-normalisation (intensity_normalisation=\"standardisation\").\n",
    "\n",
    "In addition, we need to define parameters related to intensity discretisation for computing histogram-based and texture features. Since intensities were normalised using z-normalisation, we will use a fixed bin number algorithm `(base_discretisation_method=\"fixed_bin_number\")` with 16 bins `(base_discretisation_n_bins=16)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c4d69-2c44-4126-9ba6-33044f224b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an empty list to store the DataFrames\n",
    "all_features_list = []\n",
    "\n",
    "# Loop through the selected_patients DataFrame\n",
    "for index, row in selected_patients.iterrows():\n",
    "    # Set image_path and seg_path for each row\n",
    "    image_path = \"tciaDownload/\" + row['ReferencedSeriesInstanceUID']\n",
    "    seg_path = \"tciaDownload/\" + row['SeriesInstanceUID'] + \"/1-1.dcm\"\n",
    "    \n",
    "    # Extract parameters for each image series\n",
    "    features = extract_features(\n",
    "        image=image_path,\n",
    "        mask=seg_path,\n",
    "        roi_name=\"GTV_Mass\",\n",
    "        by_slice=True,\n",
    "        intensity_normalisation=\"standardisation\",\n",
    "        new_spacing=1.0,\n",
    "        base_discretisation_method=\"fixed_bin_number\",\n",
    "        base_discretisation_n_bins=16\n",
    "    )\n",
    "    \n",
    "    # Extend the list of DataFrames\n",
    "    all_features_list.extend(features)\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "all_features = pd.concat(all_features_list, ignore_index=True)\n",
    "all_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229f4147-5c16-474d-94d0-51ee773ce5eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "This results in a pandas.DataFrame that has a row per image and mask. The first several columns contain parameters related to that image and mask, and how these were processed. After these, feature values are shown. These can be used for, e.g., machine learning using `scikit-learn <https://scikit-learn.org/stable/>`__ or `familiar <https://cran.r-project.org/web/packages/familiar/index.html>`__."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
