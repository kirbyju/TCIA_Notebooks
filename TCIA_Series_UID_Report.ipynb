{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "You can download and run this notebook locally, or you can run it for free in a cloud environment using Colab or Sagemaker Studio Lab:\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kirbyju/TCIA_Notebooks/blob/main/TCIA_Series_UID_Report.ipynb)\n",
        "\n",
        "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github.com/kirbyju/TCIA_Notebooks/blob/main/TCIA_Series_UID_Report.ipynb)"
      ],
      "metadata": {
        "id": "OA_CwnKI1R4-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmXfYFZtja2F"
      },
      "source": [
        "# Summary\n",
        "\n",
        "This notebook can be used to generate a collection-oriented summary reports to help understand the contents of a TCIA manifest or a spreadsheet/list of TCIA Series Instance UIDs.  \n",
        "\n",
        "The [manifest files are used with the NBIA Data Retriever](https://wiki.cancerimagingarchive.net/x/egOnAg) to download DICOM data from TCIA.  Manifest files to download full collections can be found on their respective homepages.  Custom manifests can also be created via our search portal at https://nbia.cancerimagingarchive.net.\n",
        "\n",
        "It is also possible to use the Export Metadata function on the \"cart\" page of https://nbia.cancerimagingarchive.net or use the [REST API](https://wiki.cancerimagingarchive.net/x/NIIiAQ) to create spreadsheets or lists of Series Instance UIDs of interest.\n",
        "\n",
        "This notebook will provide a series-level metadata report and then help you prepare the data for use by the **reportCollectionSummary()** function in **tcia_utils**, which summarizes the data by ingesting the Series Instance UIDs (series_data) and returns the following:\n",
        "\n",
        "    - Collections: List of unique collections (1 per row)\n",
        "    - DOIs: List of unique values by collection\n",
        "    - Modalities: List of unique values by collection\n",
        "    - Licenses: List of unique values by collection\n",
        "    - Manufacturers: List of unique values in the collection\n",
        "    - Body Parts: List of unique values by collection\n",
        "    - Subjects: Number of subjects by collection\n",
        "    - Studies: Number of studies by collection\n",
        "    - Series: Number of series by collection\n",
        "    - Images: Number of images by collection\n",
        "    - Disk Space: Formatted as KB/MB/GB/TB/PB by collection\n",
        "    - TimeStamp Min: Earliest TimeStamp date by collection\n",
        "    - TimeStamp Max: Latest TimeStamp date by collection\n",
        "    - UniqueTimestamps: List of dates on which new series were published by collection\n",
        "\n",
        "Parameters:\n",
        "\n",
        "    series_data: The input data to be summarized (expects JSON by default).\n",
        "    input_type: Defaults to dataframe if not populated.  \n",
        "                Set to 'list' for python list, or 'manifest' for *.TCIA manifest file.\n",
        "                If manifest is used, series_data should be the path to the TCIA manifest file.\n",
        "    format (str): Output format (default is dataframe, 'csv' for CSV file, 'chart' for charts).\n",
        "    api_url: Only necessary if input_type = list or manifest.\n",
        "            Set to 'restricted' for limited-access collections or\n",
        "            'nlst' for National Lung Screening trial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqulqBEDMSS6"
      },
      "source": [
        "# 1 Setup\n",
        "\n",
        "Install the latest release of [**tcia_utils**](https://pypi.org/project/tcia-utils/) and Pandas if you haven't already."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP4VRfgg-QXU"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade -q tcia-utils\n",
        "!pip install -q pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the modules we'll need."
      ],
      "metadata": {
        "id": "FIIqNiR1RYyM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3zEqnxi9rk2"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import requests\n",
        "import pandas as pd\n",
        "from tcia_utils import nbia\n",
        "api_url = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uMbL1nwIJ5f"
      },
      "source": [
        "# 2 Create a Token (optional)\n",
        "If you're working with any restricted collections, you must enter your TCIA login/password to create a token.  If not, you can skip this step.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgn4YvSa9GBZ"
      },
      "outputs": [],
      "source": [
        "# set api_url to 'restricted' in report query if token is created\n",
        "api_url = \"restricted\"\n",
        "\n",
        "nbia.getToken()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EdHnIZTF3Xt"
      },
      "source": [
        "# 3 Prepare your Series UIDs\n",
        "\n",
        "If you already have the file containing your series UIDs saved on the machine where this notebook is running you can skip this step. Otherwise:\n",
        "\n",
        "1. To import a file to Colab from your hard drive, use the menu on the left sidebar to upload it.\n",
        "2. To import a file from the web (e.g. TCIA), use the command in the next cell by updating it with the URL of the file you want to analyze.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpbyz-Wi-MqK"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL: import your UID file from the web\n",
        "url = \"https://URL_on_TCIA/manifest.tcia\"\n",
        "local_filename = \"manifest.tcia\"\n",
        "\n",
        "manifest = requests.get(url)\n",
        "with open(local_filename, 'wb') as f:\n",
        "    f.write(manifest.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHbh-qSHDhs3"
      },
      "source": [
        "Next we'll read in the UIDs from your file into a python list.  If you're using a manifest file, the code below will put the Series UIDs into a list while ignoring the parameter text.  \n",
        "\n",
        "If you're using a custom text/csv file of UIDs it will insert all rows into the list.  You must verify the file is formatted correctly **(one UID per row with no column header or commas)** or you may encounter errors.\n",
        "\n",
        "In cases where you're working with a large set of data this code will split things up into groups of 10,000 series UIDs so that the server doesn't time out when you try to generate the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dyvgm8VRDzG-"
      },
      "outputs": [],
      "source": [
        "# enter manifest path/filename\n",
        "manifest = \"manifest.tcia\"\n",
        "\n",
        "# converts manifest to list of UIDs\n",
        "uids = nbia.manifestToList(manifest)\n",
        "\n",
        "# break up the list into smaller chunks if needed\n",
        "chunk_size = 10000\n",
        "if len(uids) > chunk_size:\n",
        "    chunked_uids = list()\n",
        "    for i in range(0, len(uids), chunk_size):\n",
        "        chunked_uids.append(uids[i:i+chunk_size])\n",
        "    # Count how many chunks\n",
        "    chunk_count = len(chunked_uids)\n",
        "    print(\"Your data has been imported and split into\", chunk_count, \"groups.\")\n",
        "else:\n",
        "    chunk_count = 0\n",
        "    print(\"Your data has been imported.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHLc9W4Iei21"
      },
      "source": [
        "# 4 Download series metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGDqJrkmNPJL"
      },
      "source": [
        "Using the next step you can create a dataframe and save **scan_metadata.csv** containing the Collection Name, Subject ID, Study UID, Study Description, Study Date, Series UID, Series Description, Number of Images, File Size (Bytes), Modality, Manufacturer, Data Description URI (DOI), SOP Class UID, License Name, and License URL for each scan.\n",
        "\n",
        "**Note:** Due to its size (> 26,000 patients!) the [National Lung Screening Trial](https://doi.org/10.7937/TCIA.HMQ8-J677) resides on a separate server.  If you'd like to create a report about this collection use the 2nd option below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use for regular collections\n",
        "count = 0\n",
        "\n",
        "if chunk_count == 0:\n",
        "    df = nbia.getSeriesList(uids)\n",
        "else:\n",
        "    dfs = []  # create an empty list to store DataFrames\n",
        "    for x in chunked_uids:\n",
        "        str_count = str(count)\n",
        "        chunk_df = nbia.getSeriesList(x, csv_filename=\"scan_metadata_\" + str_count)\n",
        "        dfs.append(chunk_df)  # append the DataFrame for this chunk to the list\n",
        "        count += 1\n",
        "\n",
        "    # concatenate all the DataFrames in the list into a single DataFrame\n",
        "    df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "display(df)\n"
      ],
      "metadata": {
        "id": "AEe04x3V02K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use for NLST collection\n",
        "api_url = \"nlst\"\n",
        "count = 0\n",
        "\n",
        "if chunk_count == 0:\n",
        "    df = nbia.getSeriesList(uids, api_url = api_url)\n",
        "else:\n",
        "    dfs = []  # create an empty list to store DataFrames\n",
        "    for x in chunked_uids:\n",
        "        str_count = str(count)\n",
        "        chunk_df = nbia.getSeriesList(x, api_url = \"nlst\", csv_filename = \"scan_metadata_\" + str_count)\n",
        "        dfs.append(chunk_df)  # append the DataFrame for this chunk to the list\n",
        "        count += 1\n",
        "\n",
        "    # concatenate all the DataFrames in the list into a single DataFrame\n",
        "    df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "display(df)"
      ],
      "metadata": {
        "id": "knY9A8MUZtRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the summary report\n",
        "Now we can use the metadata we've downloaded to create the summary report."
      ],
      "metadata": {
        "id": "ldXoxgIIaBSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rename df columns to match expected input\n",
        "df = df.rename(columns={'Subject ID': 'PatientID',\n",
        "                                    'Study UID': 'StudyInstanceUID',\n",
        "                                    'Series ID': 'SeriesInstanceUID',\n",
        "                                    'Number of images': 'ImageCount',\n",
        "                                    'Collection Name': 'Collection',\n",
        "                                    'File Size (Bytes)': 'FileSize',\n",
        "                                    'Data Description URI': 'CollectionURI',\n",
        "                                    'License Name': 'LicenseName',\n",
        "                                    'Series Number': 'SeriesNumber',\n",
        "                                    'License URL': 'LicenseURI'})\n",
        "\n",
        "nbia.reportCollectionSummary(df, format = \"chart\")"
      ],
      "metadata": {
        "id": "UPp0K5IpaSZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYXsNGcY93B8"
      },
      "source": [
        "# Acknowledgements\n",
        "TCIA is funded by the [Cancer Imaging Program (CIP)](https://imaging.cancer.gov/), a part of the United States [National Cancer Institute (NCI)](https://www.cancer.gov/), and is managed by the [Frederick National Laboratory for Cancer Research (FNLCR)](https://frederick.cancer.gov/).\n",
        "\n",
        "This notebook was created by [Justin Kirby](https://www.linkedin.com/in/justinkirby82/).  If you leverage this notebook or any TCIA datasets in your work, please be sure to comply with the [TCIA Data Usage Policy](https://wiki.cancerimagingarchive.net/x/c4hF). In particular, make sure to cite the DOI(s) for the specific TCIA datasets you used in addition to the following paper!\n",
        "\n",
        "## TCIA Citation\n",
        "\n",
        "Clark, K., Vendt, B., Smith, K., Freymann, J., Kirby, J., Koppel, P., Moore, S., Phillips, S., Maffitt, D., Pringle, M., Tarbox, L., & Prior, F. (2013). The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository. Journal of Digital Imaging, 26(6), 1045â€“1057. https://doi.org/10.1007/s10278-013-9622-7"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}