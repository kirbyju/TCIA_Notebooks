{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirbyju/TCIA_Notebooks/blob/main/TCIA_REST_API_Queries_for_Public_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "\n",
        "Access to large, high-quality datasets is essential for researchers to understand disease and precision medicine pathways, especially in cancer. However, HIPAA constraints make sharing medical images outside an individual institution complex. [The Cancer Imaging Archive (TCIA)](https://www.cancerimagingarchive.net/) is a public service funded by the National Cancer Institute that addresses this challenge by providing hosting and de-identification services that take major burdens of data sharing off researchers. \n",
        "\n",
        "**This notebook is focused on basic use cases for leveraging TCIA's REST APIs to execute queries to learn about open-access datasets that don't require a user account.**  If you're interested in additional TCIA notebooks and coding examples, check out the tutorials at https://github.com/kirbyju/TCIA_Notebooks. You can also view a list of GitHub repositories that have tagged themself as relevant to TCIA at https://github.com/topics/tcia-dac."
      ],
      "metadata": {
        "id": "KmXfYFZtja2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5eENqx-twtkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Learn About Available Collections on the TCIA Website\n",
        "\n",
        "[Browsing Collections](https://www.cancerimagingarchive.net/collections) and viewing [Analysis Results](https://www.cancerimagingarchive.net/tcia-analysis-results/) of datasets on TCIA are the easiest ways to become familiar with what is available. These pages will help you quickly identify datasets of interest, find valuable supporting data that are not available via our APIs (e.g. clinical spreadsheets and non-DICOM segmentation data), and answer the most common questions you might have about the datasets.  "
      ],
      "metadata": {
        "id": "AruUGe3lmjkh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmeqJoR5k9z0"
      },
      "source": [
        "# 2 REST API Overview \n",
        "TCIA uses software called NBIA to manage DICOM data. The NBIA REST APIs are provided for the search and download functions used in the TCIA radiology portal and allow access to both public and limited access collections.\n",
        "1. The [NBIA Search REST APIs](https://wiki.cancerimagingarchive.net/x/fILTB) allow you to perform basic queries and download data from **public** collections. These APIs do not require a TCIA account.\n",
        "2. The [NBIA Search with Authentication REST APIs](https://wiki.cancerimagingarchive.net/x/X4ATBg) allow you to perform basic queries and download data from **public and limited-access** collections. These APIs require a TCIA account to create authentication tokens.\n",
        "3. The [NBIA Advanced REST APIs](https://wiki.cancerimagingarchive.net/x/YoATBg) also allow access to **public and limited-access** collections, but provide query endpoints mostly geared towards developers seeking to integrate searching and downloading TCIA data into web and desktop applications. This API requires a TCIA account to create authentication tokens.\n",
        "\n",
        "This notebook will focus on the fully public [NBIA Search REST APIs](https://wiki.cancerimagingarchive.net/x/fILTB). If you'd like to see examples using the APIs that require authentication, check out [this notebook](https://github.com/kirbyju/TCIA_Notebooks/blob/main/ACNS0332/ACNS0332.ipynb), which shows many similar examples with the additional steps necessary to create a secure token using your TCIA login credentials.\n",
        "\n",
        "***Note:*** Many of the examples below allow for additional query parameters to refine your results. These are covered in the documentation links above."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Setting the Base URLs\n",
        "The URL for accessing the Search APIs changes slightly depending on whether or not you would like to access the [National Lung Screening Trial (NLST)](https://doi.org/10.7937/TCIA.HMQ8-J677) collection, which lives on its own server due to its size (26,000+ patients, ~13 TBytes). Here are the base URLs:\n",
        "\n",
        "* All other Collections - https://services.cancerimagingarchive.net/nbia-api/services/v1/\n",
        "* NLST - https://services.cancerimagingarchive.net/nlst-api/services/v1/\n",
        "\n",
        "Let's set those as variables and also import a few modules we'll need later.\n"
      ],
      "metadata": {
        "id": "nj6P7YCmll4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set API base URLs\n",
        "\n",
        "base_url = \"https://services.cancerimagingarchive.net/nbia-api/services/v1/\"\n",
        "nlst_url = \"https://services.cancerimagingarchive.net/nlst-api/services/v1/\"\n",
        "\n",
        "# imports\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import json"
      ],
      "metadata": {
        "id": "FlK684ooivTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Query Examples\n",
        "Let's start by getting a list of available Collections (datasets) and then we'll dig into specific Collections in more detail."
      ],
      "metadata": {
        "id": "iao1mstCf8Vl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Get a List of Collections "
      ],
      "metadata": {
        "id": "fwj_OZjphcWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of available collections as JSON\n",
        "\n",
        "data_url = base_url + \"getCollectionValues\"\n",
        "data = requests.get(data_url).json()\n",
        "print(json.dumps(data, indent=2))\n"
      ],
      "metadata": {
        "id": "II1o1709zq1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 List Modalities or Body Parts Examined in a Collection\n",
        "Let's choose a Collection from the list above and find out more about what modalities and body parts it contains. We'll define these as functions so we can use them as part of more complex queries later in the notebook."
      ],
      "metadata": {
        "id": "1amXAIvsgQLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to return modalities for a collection as JSON\n",
        "\n",
        "# Choose a collection of interest\n",
        "collection = \"TCGA-LUAD\"\n",
        "\n",
        "# create the function\n",
        "def getModality(collection):\n",
        "    data_url = base_url + \"getModalityValues?Collection=\" + collection\n",
        "    data = requests.get(data_url)\n",
        "    if data.text != \"\":\n",
        "        return data.json()\n",
        "    else:\n",
        "        print(\"Collection not found.\")\n",
        "\n",
        "# call the function\n",
        "getModality(collection)"
      ],
      "metadata": {
        "id": "0koEKWjmieYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to return body parts examined for a collection as JSON\n",
        "collection = \"TCGA-LUAD\"\n",
        "\n",
        "def getBodyPart(collection):\n",
        "    data_url = base_url + \"getBodyPartValues?Collection=\" + collection\n",
        "    data = requests.get(data_url)\n",
        "    if data.text != \"\":\n",
        "        return data.json()\n",
        "    else:\n",
        "        print(\"Collection not found.\")\n",
        "\n",
        "getBodyPart(collection)"
      ],
      "metadata": {
        "id": "aQBt2TrC6m0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Exploring Patient, Study, and Scan Metadata\n",
        "You can use the /getPatient endpoint to obtain details about species, gender, and ethnicity where available for a given collection. You can also learn whether the subject is a [phantom](https://www.nist.gov/physics/what-are-imaging-phantoms) or not."
      ],
      "metadata": {
        "id": "1EHAjkALWsGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve patient details as JSON and create pandas dataframe w/ optional file export\n",
        "\n",
        "# Choose a collection of interest\n",
        "collection=\"CPTAC-CCRCC\"\n",
        "\n",
        "data_url = base_url + \"getPatient?Collection=\" + collection\n",
        "data = requests.get(data_url)\n",
        "\n",
        "if data.text != \"\":\n",
        "    df = pd.DataFrame(data.json())\n",
        "    display(df)\n",
        "    # optional - save to JSON or CSV file\n",
        "    df.to_csv(collection+'_patient_metadata.csv')\n",
        "    # df.to_json(collection+'_patient_metadata.json')\n",
        "else:\n",
        "    print(\"Collection not found.\")\n"
      ],
      "metadata": {
        "id": "k4Ge-Z-9H_hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an example that does the same thing with the NLST collection, which is living on its own server and uses the slightly modified API URL.  Any of the other queries shown in the notebook should work simply by setting the collection variable to \"NLST\" and updating \"base_url\" to the \"nlst_url\" in the \"data_url\" variable as shown here."
      ],
      "metadata": {
        "id": "kv8RCpe30TR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve patient details as JSON and create pandas dataframe w/ optional file export\n",
        "\n",
        "# Choose a collection of interest\n",
        "collection=\"NLST\"\n",
        "\n",
        "# NOTE: we are using the \"nlst_url\" variable rather than the general \"base_url\"\n",
        "data_url = nlst_url + \"getPatient?Collection=\" + collection\n",
        "data = requests.get(data_url)\n",
        "\n",
        "if data.text != \"\":\n",
        "    df = pd.DataFrame(data.json())\n",
        "    display(df)\n",
        "    # optional - save to JSON or CSV file\n",
        "    df.to_csv(collection+'_patient_metadata.csv')\n",
        "    # df.to_json(collection+'_patient_metadata.json')\n",
        "else:\n",
        "    print(\"Collection not found.\")"
      ],
      "metadata": {
        "id": "gMC3WCQ20cfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The /getStudy endpoint can be used to obtain study/visit details such as the anonymized study date, subject's age at the time of visit, number of scans acquired at each timepoint, and more."
      ],
      "metadata": {
        "id": "XbecJEQGfZ5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getStudy details for collection and create pandas dataframe w/ optional file export\n",
        "\n",
        "collection=\"CPTAC-CCRCC\"\n",
        "\n",
        "data_url = base_url + \"getPatientStudy?Collection=\" + collection\n",
        "data = requests.get(data_url)\n",
        "\n",
        "if data.text != \"\":\n",
        "    df = pd.DataFrame(data.json())\n",
        "    display(df)\n",
        "    # optional - save to JSON or CSV file\n",
        "    df.to_csv(collection+'_study_metadata.csv')\n",
        "    # df.to_json(collection+'_study_metadata.json')\n",
        "else:\n",
        "    print(\"Collection not found.\")"
      ],
      "metadata": {
        "id": "ivLAjjuK8nPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also create reports that give useful metadata about each scan in the dataset (e.g. series description, modality, scanner manufacturer and software version, number of images). You must choose a collection, but modality is optional.\n",
        "\n",
        "We'll define this as a function so we can use the JSON output in a more complex query later, but we'll display it in a dataframe here so it's easier to view and export to a file (if desired).  "
      ],
      "metadata": {
        "id": "bEbkXARGg6W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to return scan/series metadata for a collection as JSON \n",
        "# modality is optional\n",
        "\n",
        "collection = \"LIDC-IDRI\"\n",
        "modality = \"\"\n",
        "\n",
        "def getSeries(collection, modality=\"\"):\n",
        "    if modality != \"\":\n",
        "        data_url = base_url + \"getSeries?Collection=\" + collection + \"&Modality=\" + modality\n",
        "        data = requests.get(data_url)\n",
        "        if data.text != \"\":\n",
        "            return data.json()\n",
        "        else:\n",
        "            print(\"No results: Please check to make sure the Collection \" + collection + \" exists and it contains \" + modality + \" modality.\")\n",
        "    else:\n",
        "        data_url = base_url + \"getSeries?Collection=\" + collection\n",
        "        data = requests.get(data_url)\n",
        "        if data.text != \"\":\n",
        "            return data.json()\n",
        "        else:\n",
        "            print(\"Collection not found.\")\n",
        "\n",
        "# call the function and save the results\n",
        "data = getSeries(collection, modality)\n",
        "\n",
        "# load results to a dataframe\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# optional - save to JSON or CSV file\n",
        "# df.to_csv(collection+'_scan_metadata.csv')\n",
        "# df.to_json(collection+'_scan_metadata.json')"
      ],
      "metadata": {
        "id": "M34I2o90kofo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Advanced Queries\n",
        "Here are some additional examples that can be useful to address common questions about TCIA's datasets. For these we will rely on some of the functions we defined earlier in the notebook."
      ],
      "metadata": {
        "id": "zwndv4gJBz1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find out how many patients, which modalities and which body parts are in a collection\n",
        "\n",
        "# set collection of interest\n",
        "collection = \"QIN-PROSTATE-Repeatability\"\n",
        "\n",
        "# get list of patients in Collection\n",
        "data_url = base_url + \"getPatient?Collection=\" + collection\n",
        "data = requests.get(data_url)\n",
        "\n",
        "if data.text != \"\":\n",
        "    # get modalities for collection\n",
        "    modalities = getModality(collection)\n",
        "    clean_modalities = set(item['Modality'] for item in modalities)\n",
        "    # get body parts for collection\n",
        "    bodyParts = getBodyPart(collection)\n",
        "    clean_bodyParts = set()\n",
        "    # replace null bodyParts with \"Not Specified\"\n",
        "    for item in bodyParts:\n",
        "        if len(item):\n",
        "            clean_bodyParts.add(item['BodyPartExamined'])\n",
        "        else:\n",
        "            clean_bodyParts.add('Not Specified')\n",
        "    # print cleaned up results\n",
        "    print(collection, 'has', len(data.json()), 'patients,',\n",
        "        clean_modalities, 'modalities, and',\n",
        "        clean_bodyParts, 'anatomic entities')\n",
        "else:\n",
        "    print(\"Collection not found.\")"
      ],
      "metadata": {
        "id": "O9v6sVfePaUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate summary statistics for a given collection \n",
        "collection = \"CPTAC-LSCC\"\n",
        "\n",
        "# Call the getSeries function we created above\n",
        "data = getSeries(collection)\n",
        "\n",
        "# convert the output to dataframe\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Summarize patients\n",
        "print('Summary Statistics\\n')\n",
        "print('Subjects: ', len(df['PatientID'].value_counts()), 'subjects')\n",
        "print('Subjects: ', len(df['StudyInstanceUID'].value_counts()), 'studies')\n",
        "print('Subjects: ', len(df['SeriesInstanceUID'].value_counts()), 'series')\n",
        "print('Images: ', df['ImageCount'].sum(), 'images\\n')\n",
        "\n",
        "# Summarize modalities\n",
        "print(\"Series Counts - Modalities:\")\n",
        "print(df['Modality'].value_counts(dropna=False),'\\n')\n",
        "\n",
        "# Summarize body parts\n",
        "print(\"Series Counts - Body Parts Examined:\")\n",
        "print(df['BodyPartExamined'].value_counts(dropna=False),'\\n')\n",
        "\n",
        "# Summarize manufacturers\n",
        "print(\"Series Counts - Device Manufacturers:\")\n",
        "print(df['Manufacturer'].value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "CzkViZxej3ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get patient counts for a given modality across all Collections\n",
        "# this is particularly useful for finding Collections w/ segmentation labels (SEG/RTSTRUCT)\n",
        "\n",
        "modality = \"SEG\"\n",
        "\n",
        "data_url = base_url + \"getCollectionValues\"\n",
        "data = requests.get(data_url)\n",
        "\n",
        "if data.text != \"\":\n",
        "    notFound=[]\n",
        "    data = data.json()\n",
        "    for x in data:\n",
        "        collection = x['Collection']\n",
        "        patient_url = base_url + \"getPatientByCollectionAndModality?Collection=\" + collection + \"&Modality=\" + modality\n",
        "        patients = requests.get(patient_url)\n",
        "        if patients.text != \"\":\n",
        "            patients = patients.json()\n",
        "            print(collection, 'has', len(patients), 'patients with', modality, 'modality') \n",
        "        else:\n",
        "            notFound.append(collection)\n",
        "    print('The following collections have no patients with', modality, 'modality:', notFound)\n",
        "else:\n",
        "    print(\"Modality not found.\")"
      ],
      "metadata": {
        "id": "Stkuq_-LXISg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe that shows patient counts, modalities, body parts for all collections\n",
        "# note: this can take >6 minutes to run\n",
        "\n",
        "resultsList = []\n",
        "\n",
        "# get list of available collections\n",
        "collection_url = base_url + \"getCollectionValues\"\n",
        "collection_data = requests.get(collection_url).json()\n",
        "\n",
        "# loop through list of collections to populate dataframe\n",
        "for x in collection_data:\n",
        "    collectionName = x['Collection']\n",
        "    patient_url = base_url + \"getPatient?Collection=\" + collectionName\n",
        "    patients = requests.get(patient_url).json()\n",
        "    clean_PatientIds = set(item['PatientId'] for item in patients)\n",
        "    patientCount = len(clean_PatientIds)\n",
        "    modality_url = base_url + \"getModalityValues?Collection=\" + collectionName\n",
        "    modalities = requests.get(modality_url).json()\n",
        "    clean_modalities = set(item['Modality'] for item in modalities)\n",
        "    bodyPart_url = base_url + \"getBodyPartValues?Collection=\" + collectionName\n",
        "    bodyParts = requests.get(bodyPart_url).json()\n",
        "    clean_bodyParts = set()\n",
        "    for item in bodyParts:\n",
        "        if len(item):\n",
        "            clean_bodyParts.add(item['BodyPartExamined'])\n",
        "        else:\n",
        "            clean_bodyParts.add('Not Specified')\n",
        "    data = [collectionName, patientCount, clean_modalities, clean_bodyParts]\n",
        "    resultsList.append(data)\n",
        "    df = pd.DataFrame(columns=['Collection', 'Subjects', 'Modalities', 'BodyParts'], data=resultsList)\n",
        "    \n",
        "display(df)\n",
        "\n",
        "# optional export to CSV\n",
        "# df.to_csv('collection_metadata.csv')"
      ],
      "metadata": {
        "id": "6ZMlju-weMbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "Working with TCIA's REST APIs can be useful for building custom queries and cohorts of imaging data.  The next logical step would be to download and visualize the data.  You can learn more about how to do that in the other notebooks at https://github.com/kirbyju/TCIA_Notebooks. "
      ],
      "metadata": {
        "id": "0TjIRzCEEIFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Acknowledgements\n",
        "TCIA is funded by the [Cancer Imaging Program (CIP)](https://imaging.cancer.gov/), a part of the United States [National Cancer Institute (NCI)](https://www.cancer.gov/), and is managed by the [Frederick National Laboratory for Cancer Research (FNLCR)](https://frederick.cancer.gov/).\n",
        "\n",
        "This notebook was created by [Justin Kirby](https://www.linkedin.com/in/justinkirby82/) and Qinyan Pan. If you leverage this notebook or any TCIA datasets in your work, please be sure to comply with the [TCIA Data Usage Policy](https://wiki.cancerimagingarchive.net/x/c4hF). In particular, make sure to cite the DOI(s) for the specific TCIA datasets you used in addition to the following paper!\n",
        "\n",
        "## TCIA Citation\n",
        "\n",
        "Clark, K., Vendt, B., Smith, K., Freymann, J., Kirby, J., Koppel, P., Moore, S., Phillips, S., Maffitt, D., Pringle, M., Tarbox, L., & Prior, F. (2013). The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository. Journal of Digital Imaging, 26(6), 1045â€“1057. https://doi.org/10.1007/s10278-013-9622-7"
      ],
      "metadata": {
        "id": "DYXsNGcY93B8"
      }
    }
  ]
}