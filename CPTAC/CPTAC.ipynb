{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhJ1PywgTDmh"
      },
      "source": [
        "You can download and run this notebook locally, or you can run it for free in a cloud environment using Colab or Sagemaker Studio Lab:\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kirbyju/TCIA_Notebooks/blob/main/CPTAC/CPTAC.ipynb)\n",
        "\n",
        "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github.com/kirbyju/TCIA_Notebooks/blob/main/CPTAC/CPTAC.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmXfYFZtja2F"
      },
      "source": [
        "# Analyzing DICOM images and annotations from the CPTAC datasets hosted on TCIA\n",
        "\n",
        "This notebook is focused on accessing the [Clinical Proteomic Tumor Analysis Consortium collections](https://wiki.cancerimagingarchive.net/display/Public/CPTAC+Imaging+Proteomics) hosted on The Cancer Imaging Archive(TCIA).  These datasets include radiology and histopathology images hosted on TCIA as well as proteomic, genomic and clinical data hosted in the Proteomic Data Commons (PDC) and Genomic Data Commons (GDC).  \n",
        "\n",
        "The National Cancer Institute has also funded an activity to generate and publish annotations (3d segmentation labels and seed points) on TCIA to help jumpstart research on tumor detection, auto-segmentation methods and generating radiomics imaging features which can be compared with the proteomic, genomic and clinical data.  **This notebook is focused on:**\n",
        "\n",
        "1. Demonstrating how to access the radiology images and tumor annotations\n",
        "2. Generating radiomic features from the 3D tumor segmentations using [MIRP](https://github.com/oncoray/mirp)\n",
        "3. Extracting the corresponding clinical data from GDC to facilitate correlation with the image features.\n",
        "4. Leveraging potential genomic and proteomic classification data from [publications written by the Clinical Proteomic Tumor Analysis Consortium](https://proteomics.cancer.gov/resources/milestones-and-publications).\n",
        "\n",
        "**Note:** Users of this notebook may also find the [CPTAC python package](https://github.com/PayneLab/cptac) useful for working with the non-image data types.  This repository includes documentation about how to access genomic, proteomic and clinical data for CPTAC subjects using python dataframes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqulqBEDMSS6"
      },
      "source": [
        "# 1 Setup\n",
        "\n",
        "The following installs and imports the necessary Python packages and runs a few conditional steps if you're using Google Colab to adjust log settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP4VRfgg-QXU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "!{sys.executable} -m pip install --upgrade -q tcia_utils\n",
        "!{sys.executable} -m pip install --upgrade -q altair\n",
        "!{sys.executable} -m pip install --upgrade -q mirp\n",
        "!{sys.executable} -m pip install --upgrade -q simpleDicomViewer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3zEqnxi9rk2"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import io\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "from tcia_utils import nbia_v4 as nbia\n",
        "from simpleDicomViewer import dicomViewer\n",
        "from mirp import extract_mask_labels\n",
        "from mirp import extract_image_parameters\n",
        "from mirp import extract_images\n",
        "from mirp import extract_features\n",
        "\n",
        "# set logging level to INFO in Google Colab (not necessary in Jupyter)\n",
        "if 'google.colab' in sys.modules:\n",
        "  import logging\n",
        "\n",
        "  for handler in logging.root.handlers[:]:\n",
        "      logging.root.removeHandler(handler)\n",
        "\n",
        "  # Set handler with level = info\n",
        "  logging.basicConfig(format='%(asctime)s:%(levelname)s:%(message)s',\n",
        "                      level=logging.INFO)\n",
        "\n",
        "  print(\"Google Colab Logging set to INFO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AruUGe3lmjkh"
      },
      "source": [
        "# 2 Learn about the datasets\n",
        "\n",
        "TCIA maintains a [summary page for CPTAC](https://wiki.cancerimagingarchive.net/display/Public/CPTAC+Imaging+Proteomics) that details all available radiology and digitized histopathology we host.  \n",
        "\n",
        "As previously mentioned, a subset of these images also include annotations (tumor segmentation and seed point labels).  The annotation datasets are described at:\n",
        "\n",
        "1. [CPTAC-UCEC](https://doi.org/10.7937/89M3-KQ43): Corpus Endometrial Carcinoma\n",
        "2. [CPTAC-PDA](https://doi.org/10.7937/BW9V-BX61): Pancreatic Ductal Adenocarcinoma\n",
        "3. [CPTAC-CCRCC](https://doi.org/10.7937/SKQ4-QX48): Clear Cell Renal Carcinoma\n",
        "4. [CPTAC-HNSCC](https://doi.org/10.7937/PFEC-T641): Head and Neck Squamous Cell Carcinoma **(restricted access - Images are temporarily unavailable due to [new NIH policies](https://www.cancerimagingarchive.net/nih-controlled-data-access-policy/) on controlled-access data)**\n",
        "\n",
        "After taking a look at these collections, select the one you'd like to explore through the rest of this notebook by setting the collection variable below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEp_1Himy_R_"
      },
      "outputs": [],
      "source": [
        "collection = \"CPTAC-PDA\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRvQa63-kJIY"
      },
      "source": [
        "# 3 Downloading images and annotations with the NBIA Data Retriever\n",
        "\n",
        "TCIA uses software called NBIA to manage its DICOM data.  One way to download TCIA data is to install the NBIA Data Retriever and use the predefined manifest files that are found on the summary pages mentioned in section 2.  \n",
        "\n",
        "This tool provides a number of useful features such as auto-retry if there are any problems, saving data in an organized hierarchy on your hard drive (Collection > Patient > Study > Series > Images), and providing a CSV file containing key DICOM metadata about the images you've downloaded.  \n",
        "\n",
        "There are versions available for Windows, Mac and Linux.  If you're working from a system with a GUI you can follow the [instructions](https://wiki.cancerimagingarchive.net/display/NBIA/Downloading+TCIA+Images) to install Data Retriever on your computer.  There is also a [Linux command-line version of the NBIA Data Retriever](https://wiki.cancerimagingarchive.net/x/2QKPBQ) which is demonstrated in [this notebook](https://github.com/kirbyju/TCIA_Notebooks/blob/main/TCIA_Linux_Data_Retriever_App.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVOOJWDckJIa"
      },
      "source": [
        "# 4 Accessing the REST APIs\n",
        "The [NBIA REST APIs](https://wiki.cancerimagingarchive.net/x/ZoATBg) are another useful way for TCIA users to query metadata and download image data, which will be the focus of the rest of this notebook.  We'll rely heavily on [tcia_utils](https://pypi.org/project/tcia-utils/) to simplify accessing them.\n",
        "\n",
        "If you have questions that are not covered in this notebook you can find many additional examples in the other notebooks at https://github.com/kirbyju/TCIA_Notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6D_3Dn7kJIa"
      },
      "source": [
        "## 4.1 Exploring the data with REST API queries\n",
        "\n",
        "Let's start by looking at what body parts and modalities are contained in the collection.  For these datasets, RTSTRUCTs were used to record  the segmentations and seed points as well as to indicate scans where no tumor was found. By default, most functions from **tcia_utils** return results in JSON."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLDN4BAhbhvZ"
      },
      "outputs": [],
      "source": [
        "# count patients for each modality\n",
        "data = nbia.getModalityCounts(collection)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFrw8FAlkY8x"
      },
      "source": [
        "However, you can also use **format = \"df\"** to return the results as a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FZqff2fkJIa"
      },
      "outputs": [],
      "source": [
        "# Count patients for each body part examined,\n",
        "# return results as dataframe\n",
        "df = nbia.getBodyPartCounts(collection, format = \"df\")\n",
        "\n",
        "# rename headers and sort by PatientCount\n",
        "df.rename(columns = {'criteria':'BodyPartExamined', 'Count':'PatientCount'}, inplace = True)\n",
        "df.PatientCount = df.PatientCount.astype(int)\n",
        "display(df.sort_values(by='PatientCount', ascending=False, ignore_index = True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJQQ4-_ZkJIa"
      },
      "source": [
        "Now let's run **nbia.getPatient()** and **nbia.getStudy()** to see what we can learn about the patient cohort from the DICOM metadata.  The patient information can include things like age, gender, and ethnicity. The study information includes additional information recorded on the date the patient was scanned such as the patient's age or how many days it has been since they were diagnosed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUBlXp7P_JI8"
      },
      "outputs": [],
      "source": [
        "df = nbia.getPatient(collection, format = \"df\")\n",
        "\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IkG3w4Xb6W7"
      },
      "source": [
        "Let's use **format = \"csv\"** this time to save a CSV file in addition to returning a dataframe.  Verify that **getPatientStudy.csv** has been saved to your file system before proceeding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Kn8nhMSB5u1"
      },
      "outputs": [],
      "source": [
        "# obtain study/visit details (e.g. anonymized study date, age at the time of visit)\n",
        "df = nbia.getStudy(collection, format = \"csv\")\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BahXeSfFkJIb"
      },
      "source": [
        "We can also create a report with **nbia.getSeries()** that gives useful metadata about each scan in the dataset (e.g. series description, modality, scanner manufacturer & software version, number of images)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQVbwxCEkJIb"
      },
      "outputs": [],
      "source": [
        "# obtain scan/series metadata and save to variable for use in next example\n",
        "series = nbia.getSeries(collection, format = \"df\")\n",
        "\n",
        "display(series)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8p4rjHCkJIb"
      },
      "source": [
        "Finally, we can use the results from the getSeries() query to generate some summary statistics about the data in the collection.  Note that there are separate rows summarizing the contents of the original collection and the contents of the annotation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYS-sdd7kJIb"
      },
      "outputs": [],
      "source": [
        "# Calculate summary statistics for a given collection\n",
        "nbia.reportDoiSummary(series, input_type = \"df\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWUOGHyLkJIb"
      },
      "source": [
        "## 4.2 Downloading data with the REST API\n",
        "There are a wide variety of ways to use **downloadSeries()** to download data from TCIA.  You can learn more about this in https://github.com/kirbyju/TCIA_Notebooks/blob/main/TCIA_REST_API_Downloads.ipynb, but we'll cover a few basic use cases in this notebook.\n",
        "\n",
        "First we'll demonstrate downloading a segmentation and the corresponding image series for a single subject.  To do this we'll pull a random segmentation using the **series** dataframe we created earlier with **getSeries()**.  All annotation data is in RTSTRUCT format, so we'll filter for this in the Modality column and then use SeriesDescription to make sure we're pulling a 3d segmentation and not a seed point annotation as they're too small to visualize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFEOLIYRs33G"
      },
      "outputs": [],
      "source": [
        "random_row = series.loc[(series['Modality'] == 'RTSTRUCT') &\n",
        "                        (~series['SeriesDescription'].fillna('').str.lower().str.contains('seed'))].sample(n=1)\n",
        "segSeries = random_row['SeriesInstanceUID'].iloc[0]\n",
        "\n",
        "print(segSeries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NVZAb3qu_X4"
      },
      "source": [
        "To determine the Reference Series UID of the image data that goes with this segmentation you can use **nbia.getSegRefSeries()**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jogkmh9kvMoW"
      },
      "outputs": [],
      "source": [
        "refSeries = nbia.getSegRefSeries(segSeries)\n",
        "\n",
        "print(refSeries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkMkyHoYwC2F"
      },
      "source": [
        "Next let's download these two series by passing their UIDs as a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P-s8sZBwIIz"
      },
      "outputs": [],
      "source": [
        "nbia.downloadSeries([refSeries, segSeries], input_type= \"list\", format = 'df')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HU0fGOwvxxO"
      },
      "source": [
        "Now we can look at the images and segmentation together with **viewSeriesAnnotation()** from [simpleDicomViewer](https://pypi.org/project/simpleDicomViewer/).  Note that this function is only meant to be a  quick and dirty way to preview the data.  There are more comprehensive solutions such as [3D Slicer](https://slicer.org/) or [itkWidgets](https://github.com/kirbyju/TCIA_Notebooks/blob/main/TCIA_RTStruct_SEG_Visualization_with_itkWidgets.ipynb) if you want analyze the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZb33aCNv24K"
      },
      "outputs": [],
      "source": [
        "# Assuming you didn't change the default download options for downloadSeries\n",
        "imgPath = \"tciaDownload/\" + refSeries\n",
        "\n",
        "# The annotation path has to be a file name (not directory name).  Since there is generally\n",
        "# only one file in a segmentation series we can assume it will always be called 1-1.dcm\n",
        "segPath = \"tciaDownload/\" + segSeries + \"/1-1.dcm\"\n",
        "\n",
        "# Display the viewer\n",
        "dicomViewer.viewDicom(imgPath, segPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BcRqf0syPjv"
      },
      "source": [
        "# 5 Exploring the annotation metatadata\n",
        "\n",
        "Now let's take a look at the annotation metadata spreadsheet the authors provided.  You can download them manually from the **Annotation Summary** links in section 2 of the notebook or retrieve the one relevant to your selected collection directly into a dataframe with the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2s8JKf74y-q"
      },
      "outputs": [],
      "source": [
        "metadata_urls = {\n",
        "    \"CPTAC-CCRCC\": \"https://www.cancerimagingarchive.net/wp-content/uploads/Metadata_Report_CPTAC-CCRCC_2023_07_14.csv\",\n",
        "    \"CPTAC-PDA\": \"https://www.cancerimagingarchive.net/wp-content/uploads/Metadata_Report_CPTAC-PDA_2023_07_14.csv\",\n",
        "    \"CPTAC-HNSCC\": \"https://www.cancerimagingarchive.net/wp-content/uploads/Metadata_Report_CPTAC-HNSCC_2023_07_14.csv\",\n",
        "    \"CPTAC-UCEC\": \"https://www.cancerimagingarchive.net/wp-content/uploads/Metadata_Report_CPTAC-UCEC_2023_07_14.csv\"\n",
        "}\n",
        "\n",
        "if collection in metadata_urls:\n",
        "    spreadsheet_url = metadata_urls[collection]\n",
        "    annotation_Metadata = pd.read_csv(spreadsheet_url)\n",
        "    display(annotation_Metadata)\n",
        "else:\n",
        "    print(\"URL for collection not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whmDaenKQtEr"
      },
      "source": [
        "## Visualize StructureSetLabels\n",
        "Let's take a look at a couple of plots to help us understand the available data. First we'll look at the structure set labels together with Clinical Trial Timepoint for each subject."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U_RxSvvb2M_"
      },
      "outputs": [],
      "source": [
        "# Create the scatter plot\n",
        "scatter_plot = alt.Chart(annotation_Metadata).mark_circle().encode(\n",
        "    x=alt.X('PatientID', axis=alt.Axis(labelAngle=-45)),\n",
        "    y='StructureSetLabel',\n",
        "    color='ClinicalTrialTimePointID',\n",
        "    tooltip=['PatientID', 'StudyDate', 'SeriesDescription', 'ROIVolume', 'ClinicalTrialTimePointID', 'StructureSetLabel']\n",
        ").properties(\n",
        "    title=\"Structure Set Label by Patient ID and Clinical Trial Time Point ID\"\n",
        ").configure_axis(\n",
        "    grid=True\n",
        ").interactive()\n",
        "\n",
        "# Show the scatter plot\n",
        "scatter_plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y014dMHxx9sx"
      },
      "source": [
        "## Visualize Tumor Volumes\n",
        "Next let's compare the tumor volumes for each patient at each available Clinical Trial Timepoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxOm7FrGgxVi"
      },
      "outputs": [],
      "source": [
        "# Convert the ROIVolume column to string type\n",
        "annotation_Metadata['ROIVolume'] = annotation_Metadata['ROIVolume'].astype(str)\n",
        "\n",
        "# Remove the \"cc\" text from each value\n",
        "annotation_Metadata['ROIVolume'] = annotation_Metadata['ROIVolume'].str.replace(' cc', '')\n",
        "\n",
        "# Convert the ROIVolume column to float type\n",
        "annotation_Metadata['ROIVolume'] = pd.to_numeric(annotation_Metadata['ROIVolume'], errors='coerce')\n",
        "\n",
        "# Create the scatter plot\n",
        "scatter_plot = alt.Chart(annotation_Metadata).mark_circle().encode(\n",
        "    x=alt.X('PatientID', axis=alt.Axis(labelAngle=-45)),\n",
        "    y='ROIVolume',\n",
        "    color='StructureSetLabel',\n",
        "    tooltip=['PatientID', 'StudyDate', 'SeriesDescription', 'ROIVolume', 'ClinicalTrialTimePointID', 'StructureSetLabel']\n",
        ").properties(\n",
        "    title=\"ROI Volume by Patient ID and Clinical Trial Time Point ID\"\n",
        ").configure_axis(\n",
        "    grid=True  # Add grid lines to the plot\n",
        ").interactive()\n",
        "\n",
        "# Show the scatter plot\n",
        "scatter_plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHCTKd61SCa6"
      },
      "source": [
        "## Downloading specific subjects\n",
        "If, after reviewing these charts, you were interested to download a specific subject's imaging and annotations you can do this with the steps shown below.  Make sure to update the **patient** variable below with the PatientID you want to download."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAUr70rFKEip"
      },
      "outputs": [],
      "source": [
        "# set this to the PatientID you want to download\n",
        "patient = \"C3L-00395\"\n",
        "\n",
        "# Get instances of ReferencedSeriesInstanceUID and SeriesInstanceUID associated with the PatientID\n",
        "unique_series = annotation_Metadata.loc[annotation_Metadata['PatientID'] == patient, ['ReferencedSeriesInstanceUID', 'SeriesInstanceUID']]\n",
        "\n",
        "# Flatten it into a single list\n",
        "unique_series_list = [item for sublist in unique_series.values for item in sublist]\n",
        "\n",
        "# Remove any duplicates from the unique series list\n",
        "unique_series_list = list(set(unique_series_list))\n",
        "\n",
        "# download the series from the unique series list\n",
        "nbia.downloadSeries(unique_series_list, input_type=\"list\", format = \"df\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgkWxt-QUM3i"
      },
      "source": [
        "## Downloading in bulk\n",
        "You can also download data in bulk by filtering the dataframe for whatever you're interested in and feeding the resulting UIDs to the nbia.downloadSeries() function.  \n",
        "\n",
        "However, since these types of queries will result in much larger numbers of series to download we'll we'll set the **number** parameter in **downloadSeries()** so that it just grabs the first couple series for testing purposes.  Remove this parameter in the code below to download everything.\n",
        "\n",
        "For this example, let's assume a researcher is interested in grabbing all of the seed point annotations and the images used to create them.  You can change this to whatever other criteria you like if you want a different subset of data.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify how many test series you'd like to download\n",
        "number = 2\n",
        "\n",
        "# Get instances of ReferencedSeriesInstanceUID and SeriesInstanceUID associated with your query\n",
        "unique_series = annotation_Metadata.loc[annotation_Metadata['Annotation Type'] == \"Seed point\", ['ReferencedSeriesInstanceUID', 'SeriesInstanceUID']]\n",
        "\n",
        "# Flatten it into a single list\n",
        "unique_series_list = [item for sublist in unique_series.values for item in sublist]\n",
        "\n",
        "# Remove any duplicates from the unique series list\n",
        "unique_series_list = list(set(unique_series_list))\n",
        "\n",
        "# download the series from the unique series list\n",
        "nbia.downloadSeries(unique_series_list, input_type=\"list\", format = \"df\", number = number)"
      ],
      "metadata": {
        "id": "WTQu-cOhs_EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 Computing radiomic features with MIRP\n",
        "\n",
        "Now let's use [Medical Image Radiomics Processor (MIRP)](https://github.com/oncoray/mirp) to compute some radiomic features from the tumor segmentations.  We'll also merge in some of the metadata from the original images (saved to the **series** dataframe earlier in the notebook) that were annotated so we can see that side by side with the annotation details."
      ],
      "metadata": {
        "id": "JauXyjQM-x_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a copy of annotation_Metadata and drop the \"DICOM Type\" column\n",
        "radiomics_metadata = annotation_Metadata.drop(columns=['DICOM Type'])\n",
        "\n",
        "# Exclude rows where the \"Annotation Type\" does not equal \"Segmentation\"\n",
        "radiomics_metadata = radiomics_metadata[radiomics_metadata['Annotation Type'] == 'Segmentation']\n",
        "\n",
        "# Select the series columns we want to merge\n",
        "refSeries = series[['SeriesInstanceUID', 'Modality', 'BodyPartExamined', 'SeriesDescription', 'Manufacturer', 'ManufacturerModelName']]\n",
        "\n",
        "# Rename the columns in 'refSeries' dataframe\n",
        "refSeries = refSeries.rename(columns={\n",
        "    'SeriesInstanceUID': 'ReferencedSeriesInstanceUID',\n",
        "    'Modality': 'ReferencedSeriesModality',\n",
        "    'BodyPartExamined': 'ReferencedSeriesBodyPartExamined',\n",
        "    'SeriesDescription': 'ReferencedSeriesDescription',\n",
        "    'Manufacturer': 'ReferencedSeriesManufacturer',\n",
        "    'ManufacturerModelName': 'ReferencedSeriesManufacturerModelName'\n",
        "})\n",
        "\n",
        "# Merge 'radiomics_metadata' and 'refSeries' on the matching column\n",
        "radiomics_metadata = pd.merge(radiomics_metadata, refSeries, how='left', left_on='ReferencedSeriesInstanceUID', right_on='ReferencedSeriesInstanceUID')\n",
        "\n",
        "radiomics_metadata"
      ],
      "metadata": {
        "id": "HENDl0pe7qpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the code below to to specify whether you want to test with a few sample scans or process the entire dataset. This will download both the relevant RTSTRUCT segmentation(s) and image series used to create them."
      ],
      "metadata": {
        "id": "DCI1WH7Gv56Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the number of segmentations or use None to download the full set of scans\n",
        "num_segs = 3\n",
        "\n",
        "if num_segs is None:\n",
        "    uids_list = list(radiomics_metadata['SeriesInstanceUID']) + list(radiomics_metadata['ReferencedSeriesInstanceUID'])\n",
        "else:\n",
        "    selected_segs = radiomics_metadata.head(num_segs)\n",
        "    uids_list = list(selected_segs['SeriesInstanceUID']) + list(selected_segs['ReferencedSeriesInstanceUID'])\n",
        "\n",
        "# Pass the uids_list to nbia.downloadSeries(uids) for downloading\n",
        "nbia.downloadSeries(uids_list, input_type = \"list\")\n",
        "\n"
      ],
      "metadata": {
        "id": "biHx2PVV-zjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_segs"
      ],
      "metadata": {
        "id": "LKm_HPK2sghO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assessing image metadata\n",
        "Image metadata are important for understanding the image and how it was acquired and reconstructed. MIRP provides a function called **extract_image_parameters()** to help with this."
      ],
      "metadata": {
        "id": "MQot0mZ-r5Lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty DataFrame to store the concatenated results\n",
        "all_parameters = pd.DataFrame()\n",
        "\n",
        "# Loop through the selected_patients DataFrame\n",
        "for index, row in selected_segs.iterrows():\n",
        "    # Set seg_path for each row\n",
        "    image_path = \"tciaDownload/\" + row['ReferencedSeriesInstanceUID']\n",
        "    # Extract parameters for each image series\n",
        "    parameters = extract_image_parameters(image = image_path)\n",
        "\n",
        "    # Concatenate the results into the all_labels DataFrame\n",
        "    all_parameters = pd.concat([all_parameters, parameters])\n",
        "\n",
        "all_parameters"
      ],
      "metadata": {
        "id": "BbKg_DRzr4u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing image features\n",
        "Next we will compute our image features.  Note that certain optional parameters and pre-processing steps may be required to achieve meaningful feature results.  Since the goal of this notebook is to demonstrate a basic workflow for loading TCIA data into MIRP (not to provide a tutorial in radiomic feature analysis), we'll stick to computing morphological features which are mostly unaffected by these more advanced topics."
      ],
      "metadata": {
        "id": "HpXuVxtc0JiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty list to store the DataFrames\n",
        "all_features_list = []\n",
        "\n",
        "# Loop through the selected_patients DataFrame\n",
        "for index, row in selected_segs.iterrows():\n",
        "    # Set image_path and seg_path for each row\n",
        "    image_path = \"tciaDownload/\" + row['ReferencedSeriesInstanceUID']\n",
        "    seg_path = \"tciaDownload/\" + row['SeriesInstanceUID'] + \"/1-1.dcm\"\n",
        "\n",
        "    # Extract parameters for each image series\n",
        "    features = extract_features(\n",
        "        image=image_path,\n",
        "        mask=seg_path,\n",
        "        by_slice=True,\n",
        "        base_feature_families=[\"morphology\"]\n",
        "        #intensity_normalisation=\"standardisation\",\n",
        "        #new_spacing=1.0,\n",
        "        #base_discretisation_method=\"fixed_bin_number\",\n",
        "        #base_discretisation_n_bins=16\n",
        "    )\n",
        "\n",
        "    # Extend the list of DataFrames\n",
        "    all_features_list.extend(features)\n",
        "\n",
        "# Concatenate all DataFrames in the list\n",
        "all_features = pd.concat(all_features_list, ignore_index=True)\n",
        "all_features\n"
      ],
      "metadata": {
        "id": "A2kBwT8d0kxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kob3V1Y4pTIF"
      },
      "source": [
        "# 7 Accessing clinical data from NCI's Genomic Data Commons (GDC)\n",
        "\n",
        "There is a significant amount of supporting genomic and clinical data for these subjects in the [Genomic Data Commons](https://portal.gdc.cancer.gov/).  Here we'll provide an example showing how to obtain all available clinical data and merge it with the subset of subjects who also have annotated radiology images.  \n",
        "\n",
        "If you have any questions about this section, pleaes consult their documentation at https://docs.gdc.cancer.gov/API/Users_Guide/Getting_Started/ and their helpdesk at support@nci-gdc.datacommons.io.\n",
        "\n",
        "To begin, let's download all clinical data they have available associated with the CPTAC-3 project.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDoAfBLopdCF"
      },
      "outputs": [],
      "source": [
        "cases_endpt = 'https://api.gdc.cancer.gov/cases'\n",
        "\n",
        "filters = {\n",
        "    \"op\": \"in\",\n",
        "    \"content\":{\n",
        "        \"field\": \"project.project_id\",\n",
        "        \"value\": [\"CPTAC-3\"]\n",
        "        }\n",
        "    }\n",
        "\n",
        "fields = [\n",
        "    \"submitter_id\",\n",
        "    ]\n",
        "\n",
        "fields = ','.join(fields)\n",
        "\n",
        "expand = [ ## For the allowable values for this list, look under \"mapping\" at https://api.gdc.cancer.gov/cases/_mapping\n",
        "    \"demographic\",\n",
        "    \"diagnoses\",\n",
        "    \"diagnoses.treatments\",\n",
        "    \"exposures\",\n",
        "    \"family_histories\"\n",
        "    ]\n",
        "\n",
        "expand = ','.join(expand)\n",
        "\n",
        "params = {\n",
        "    \"filters\": json.dumps(filters),\n",
        "    \"expand\": expand,\n",
        "    \"fields\": fields,\n",
        "    \"format\": \"TSV\", ## This can be \"JSON\" too\n",
        "    \"size\": \"2000\", ## If you are including several projects, I would recommend playing with this and the \"from\" number.\n",
        "    \"from\":\"0\"\n",
        "    }\n",
        "\n",
        "response = requests.get(cases_endpt, params = params)\n",
        "\n",
        "output = response.content.decode('UTF-8')\n",
        "clinicalDf = pd.read_csv(io.StringIO(output), sep='\\t')\n",
        "\n",
        "#clinicalDf\n",
        "#clinicalDf.to_csv(\"gdc-cptac-clinical.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PUShHIvp_ME"
      },
      "source": [
        "Now let's merge the clinical data with our image annotation data so that we're only looking at subjects where we have both."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-fdbnVTyhRp"
      },
      "outputs": [],
      "source": [
        "# create new dataframe from annotation_Metadata with only unique IDs of patients with imaging\n",
        "uniquePatients = pd.DataFrame(annotation_Metadata['PatientID'].unique(), columns=['PatientID'])\n",
        "\n",
        "# Rename the patient id column in dropNaN to match annotation_Metadata\n",
        "clinicalDf = clinicalDf.rename(columns={'submitter_id': 'PatientID'})\n",
        "\n",
        "# Merge the dataframes\n",
        "mergedClinical = uniquePatients.merge(clinicalDf, how='left', on='PatientID')\n",
        "\n",
        "mergedClinical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emM3QUp6fUvY"
      },
      "source": [
        "## Visualize missing clinical data\n",
        "\n",
        "Let's investigate what types of clinical information are available and how often they are populated.  We'll drop all the columns where no information is provided and then visualize the number of times there are null values in the columns that remain."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns with all NaN values from clinical data\n",
        "cleanClinical = mergedClinical.dropna(axis=1, how='all')\n",
        "\n",
        "null_counts = cleanClinical.isnull().sum()\n",
        "\n",
        "null_df = null_counts.reset_index()\n",
        "null_df.columns = ['Column', 'Null Count']\n",
        "\n",
        "chart = alt.Chart(null_df).mark_bar().encode(\n",
        "    x=alt.X('Column', axis=alt.Axis(labelAngle=-45)),\n",
        "    y='Null Count',\n",
        "    tooltip=['Column', 'Null Count']  # Show these values on mouse-over\n",
        ").interactive()  # Enable zooming and panning\n",
        "\n",
        "chart.show()\n"
      ],
      "metadata": {
        "id": "uopd-KsP7NdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i1xWRqGXMbK"
      },
      "source": [
        "Let's say we want to understand the racial distribution of patients before we start our analysis.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZK7dknCd5yb"
      },
      "outputs": [],
      "source": [
        "# Convert the 'value_counts' to a DataFrame for Altair\n",
        "counts_df = cleanClinical['demographic.race'].value_counts().reset_index()\n",
        "counts_df.columns = ['race', 'count']\n",
        "\n",
        "# Create a pie chart with Altair\n",
        "chart = alt.Chart(counts_df).mark_arc().encode(\n",
        "    theta=alt.Theta(field='count', type='quantitative', stack=True),  # Stack ensures the pie chart is a full circle\n",
        "    color=alt.Color(field='race', type='nominal', legend=alt.Legend(title=\"Races\")),  # Add a legend for color\n",
        "    tooltip=['race', 'count']  # Optional: to display tooltips on hover\n",
        ").properties(\n",
        "    title='Subject distribution'\n",
        ")\n",
        "\n",
        "# Show the pie chart\n",
        "chart.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trwbz-gpNYRK"
      },
      "source": [
        "Let's also take a look at age distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cC7vyO56Nupa"
      },
      "outputs": [],
      "source": [
        "counts_df = cleanClinical['diagnoses.0.age_at_diagnosis'].value_counts().reset_index()\n",
        "counts_df.columns = ['age_at_diagnosis', 'count']\n",
        "\n",
        "# Convert age from days to years\n",
        "counts_df['age_at_diagnosis'] = counts_df['age_at_diagnosis'] / 365.25\n",
        "\n",
        "# Create a histogram with Altair\n",
        "hist = alt.Chart(counts_df).mark_bar().encode(\n",
        "    x=alt.X('age_at_diagnosis:Q', bin=True),  # Quantitative scale with automatic binning\n",
        "    y='count:Q',  # Quantitative scale for the count\n",
        ").properties(\n",
        "    title='Age (years) at Diagnosis'\n",
        ")\n",
        "\n",
        "# Show the histogram\n",
        "hist.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8 Genomic and Proteomic feature classification\n",
        "The Clinical Proteomic Tumor Analysis Consortium (CPTAC) brings together leading centers nationwide in a comprehensive and coordinated effort to accelerate the understanding of the molecular basis of cancer through the application of large-scale proteome and genome analysis, or proteogenomics, and to address mechanisms of treatment response, resistance, or toxicity.  They maintain a list of the consortium's most [significant milestones and publications](https://proteomics.cancer.gov/resources/milestones-and-publications).  \n",
        "\n",
        "Let's take a quick look at an example from their \"[Pan-cancer proteogenomics connects oncogenic drivers to functional states](https://doi.org/10.1016/j.cell.2023.07.014)\" study, which has a wealth of [supplemental classification data](https://www.cell.com/cms/10.1016/j.cell.2023.07.014/attachment/dcd2885a-81a2-44bd-ab35-a0440f1352b1/mmc1.xlsx) which might be interesting to try and predict using the image data.  \n",
        "\n",
        "Unfortunately Cell blocks direct programmatic access to their supplemental data files, so I've created a copy of the \"Table S1A\" tab from that file and put it on Github for convenience.  Please make sure you consult the links above for the full dataset if you're going to do any actual research with this.  This is only meant to give you an example of what's available."
      ],
      "metadata": {
        "id": "QwBzTk0COYXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "omics = pd.read_excel('https://github.com/kirbyju/TCIA_Notebooks/raw/refs/heads/main/CPTAC/cptac-pan-cancer-drivers-table-S1A.xlsx')\n",
        "\n",
        "print(omics.columns.tolist())\n",
        "\n",
        "display(omics)"
      ],
      "metadata": {
        "id": "N2G7dxLeVMUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to find out what radiology imaging data are available for these subjects let's start by saving the omic case IDs to a list."
      ],
      "metadata": {
        "id": "uNqbpSwaL2Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "omic_patients = omics['CASE_ID'].tolist()"
      ],
      "metadata": {
        "id": "9ZCY-jcELK0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll feed that case list to a tcia_utils called **getSimpleSearchWithModalityAndBodyPartPaged()**.  This function lets you do pretty much everything you can do in the Simple Search screen at https://nbia.cancerimagingarchive.net. As as a result, there are a lot of parameters but we'll just use it to request all imaging data that corresponds to any of our omic patient IDs.\n",
        "\n",
        "**Note:** if you want to include imaging data that contains faces in your search you must request access as described near the beginning of the notebook and log in with nbia.getToken() before executing the next query."
      ],
      "metadata": {
        "id": "bbXeH2zoL-hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optional step -- use if you want to include restricted data\n",
        "nbia.getToken()"
      ],
      "metadata": {
        "id": "NUihwEg5SnRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "radiology_patients = nbia.getSimpleSearchWithModalityAndBodyPartPaged(patients = omic_patients, format = 'uids')"
      ],
      "metadata": {
        "id": "5BoMk1BI4lnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we jump into downloading the data, let's take a minute to inspect what this returned.  We can do that be feeding the UID list to **nbia.reportCollectionSummary()** which will provide information about how many patients, studies, series, and images are part of your search results."
      ],
      "metadata": {
        "id": "DpwCbdeBPHM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nbia.reportCollectionSummary(radiology_patients, input_type = 'list', format = 'df')"
      ],
      "metadata": {
        "id": "oKGlA9wHPD0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you wanted a more detailed inventory of the available scans you can use **nbia.getSeriesList()** and refine the results to weed out things you're not interested in.  Let's say that we only care about reviewing CT images for our project.  All we need to do is drop everything that doesn't have a CT modality and then pass the resulting dataframe to **nbia.downloadSeries()** to save the final dataset as shown below."
      ],
      "metadata": {
        "id": "yBelEBssP4yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scan_inventory = nbia.getSeriesList(radiology_patients, format = 'df')"
      ],
      "metadata": {
        "id": "JYMG3hmSQC_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows where 'Modality' is not 'CT'\n",
        "ct_radiology = scan_inventory[scan_inventory['Modality'] == 'CT']\n",
        "\n",
        "ct_radiology"
      ],
      "metadata": {
        "id": "QSJT3K6XQxN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloadSeries expects SeriesInstanceUID to be the column name if you feed it a dataframe\n",
        "scan_inventory = scan_inventory.rename(columns={'Series ID': 'SeriesInstanceUID'})\n",
        "\n",
        "# we'll use number = 1 to just download a single example scan\n",
        "nbia.downloadSeries(scan_inventory, input_type = 'df', number = 1)"
      ],
      "metadata": {
        "id": "sINoACKMRa7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYG8cUwmLfZc"
      },
      "source": [
        "# Acknowledgements\n",
        "TCIA is funded by the [Cancer Imaging Program (CIP)](https://imaging.cancer.gov/), a part of the United States [National Cancer Institute (NCI)](https://www.cancer.gov/).  It is managed by the [Frederick National Laboratory for Cancer Research (FNLCR)](https://frederick.cancer.gov/) and hosted by the [University of Arkansas for Medical Sciences (UAMS)](https://www.uams.edu/)\n",
        "\n",
        "This notebook was created by [Justin Kirby](https://www.linkedin.com/in/justinkirby82/). If you leverage this notebook or any TCIA datasets in your work, please be sure to comply with the [TCIA Data Usage Policy](https://wiki.cancerimagingarchive.net/x/c4hF). In particular, make sure to cite the DOI(s) for the specific TCIA datasets you used in addition to the following paper!\n",
        "\n",
        "## TCIA Citation\n",
        "\n",
        "Clark, K., Vendt, B., Smith, K., Freymann, J., Kirby, J., Koppel, P., Moore, S., Phillips, S., Maffitt, D., Pringle, M., Tarbox, L., & Prior, F. (2013). The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository. Journal of Digital Imaging, 26(6), 1045–1057. https://doi.org/10.1007/s10278-013-9622-7"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SmeqJoR5k9z0",
        "CSTkcuXMgCDd",
        "7YGlC_ajggC8",
        "nj6P7YCmll4S",
        "I9_O-nq1lr7c",
        "JkCZMxa_ua6P",
        "BJEBAyTyqcU5",
        "YMIPh4vzqfN5",
        "9Zp_hWmXsKZ9"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}